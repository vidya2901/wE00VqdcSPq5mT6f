{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sapphire-cruise",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "#import tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim.downloader as api\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim import models \n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "#from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "import h2o\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "departmental-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = (\"/Users/vidyakumar/Desktop/python/apziva/potential-talents - Aspiring human resources - seeking human resources.csv\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "associate-excitement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   1   \n",
       "1   2   \n",
       "2   3   \n",
       "3   4   \n",
       "4   5   \n",
       "\n",
       "                                                                                                  job_title  \\\n",
       "0  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional   \n",
       "1                                                                            Native English Teacher at EPIK   \n",
       "2                                                                     Aspiring Human Resources Professional   \n",
       "3                                                                    People Development Coordinator at Ryan   \n",
       "4                                                           Advisory Board Member at Celal Bayar University   \n",
       "\n",
       "                              location connection  fit  \n",
       "0                       Houston, Texas         85  NaN  \n",
       "1                               Kanada      500+   NaN  \n",
       "2  Raleigh-Durham, North Carolina Area         44  NaN  \n",
       "3                        Denton, Texas      500+   NaN  \n",
       "4                       İzmir, Türkiye      500+   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data():\n",
    "    data = pd.read_csv(data_url)\n",
    "    return data\n",
    "\n",
    "data = load_data()\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "educational-proposal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104, 5)\n",
      "(54, 5)\n"
     ]
    }
   ],
   "source": [
    "# If it's the same job description in the same city, for the same job title, we consider it duplicate.\n",
    "print(data.shape)\n",
    "df_nodups = data.drop_duplicates(subset=['job_title', 'location'])\n",
    "print(df_nodups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cardiac-photographer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "job_title      0\n",
       "location       0\n",
       "connection     0\n",
       "fit           54\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodups.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "assigned-drawing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 54 entries, 0 to 103\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   id          54 non-null     int64  \n",
      " 1   job_title   54 non-null     object \n",
      " 2   location    54 non-null     object \n",
      " 3   connection  54 non-null     object \n",
      " 4   fit         0 non-null      float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 2.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_nodups.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "documentary-unemployment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>job_title_no_stpw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019 c.t. bauer college business graduate (magna cum laude) aspiring human resources professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at  English Program in Korea</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>native english teacher english program korea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people development coordinator ryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>advisory board member celal bayar university</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspiring human resources specialist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Student at Humber College and Aspiring Human Resources Generalist</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>student humber college aspiring human resources generalist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Human Resources  Senior Specialist</td>\n",
       "      <td>San Francisco Bay Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>human resources senior specialist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Seeking Human Resources  Human Resources Information System  and Generalist Positions</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>seeking human resources human resources information system generalist positions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Student at Chapman University</td>\n",
       "      <td>Lake Forest, California</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>student chapman university</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  \\\n",
       "0    1   \n",
       "1    2   \n",
       "2    3   \n",
       "3    4   \n",
       "4    5   \n",
       "5    6   \n",
       "6    7   \n",
       "7    8   \n",
       "9   10   \n",
       "10  11   \n",
       "\n",
       "                                                                                                   job_title  \\\n",
       "0   2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional   \n",
       "1                                                       Native English Teacher at  English Program in Korea    \n",
       "2                                                                      Aspiring Human Resources Professional   \n",
       "3                                                                     People Development Coordinator at Ryan   \n",
       "4                                                            Advisory Board Member at Celal Bayar University   \n",
       "5                                                                        Aspiring Human Resources Specialist   \n",
       "6                                          Student at Humber College and Aspiring Human Resources Generalist   \n",
       "7                                                                         Human Resources  Senior Specialist   \n",
       "9                      Seeking Human Resources  Human Resources Information System  and Generalist Positions   \n",
       "10                                                                             Student at Chapman University   \n",
       "\n",
       "                               location connection  fit  \\\n",
       "0                        Houston, Texas         85  NaN   \n",
       "1                                Kanada      500+   NaN   \n",
       "2   Raleigh-Durham, North Carolina Area         44  NaN   \n",
       "3                         Denton, Texas      500+   NaN   \n",
       "4                        İzmir, Türkiye      500+   NaN   \n",
       "5            Greater New York City Area          1  NaN   \n",
       "6                                Kanada         61  NaN   \n",
       "7                San Francisco Bay Area      500+   NaN   \n",
       "9             Greater Philadelphia Area      500+   NaN   \n",
       "10              Lake Forest, California          2  NaN   \n",
       "\n",
       "                                                                                    job_title_no_stpw  \n",
       "0   2019 c.t. bauer college business graduate (magna cum laude) aspiring human resources professional  \n",
       "1                                                        native english teacher english program korea  \n",
       "2                                                               aspiring human resources professional  \n",
       "3                                                                 people development coordinator ryan  \n",
       "4                                                        advisory board member celal bayar university  \n",
       "5                                                                 aspiring human resources specialist  \n",
       "6                                          student humber college aspiring human resources generalist  \n",
       "7                                                                   human resources senior specialist  \n",
       "9                     seeking human resources human resources information system generalist positions  \n",
       "10                                                                         student chapman university  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace acronymns\n",
    "df_nodups['job_title'] = df_nodups['job_title'].str.replace(\"HRIS\", \" Human Resources Information System \")\n",
    "df_nodups['job_title'] = df_nodups['job_title'].str.replace(\"HR\", \" Human Resources \")\n",
    "df_nodups['job_title'] = df_nodups['job_title'].str.replace(\"EPIK\", \" English Program in Korea \")\n",
    "df_nodups['job_title'] = df_nodups['job_title'].str.replace(\"JTI\", \" Japan Tobacco International \")\n",
    "\n",
    "#removing stopwords and making it all lowercase\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df_nodups['job_title_no_stpw'] = df_nodups['job_title'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "df_nodups['job_title_no_stpw'] = df_nodups['job_title_no_stpw'].str.lower()\n",
    "df_nodups.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "approximate-timing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>job_title_no_stpw</th>\n",
       "      <th>job_title_no_splc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019 c.t. bauer college business graduate (magna cum laude) aspiring human resources professional</td>\n",
       "      <td>ct bauer college business graduate magna cum laude aspiring human resources professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at  English Program in Korea</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>native english teacher english program korea</td>\n",
       "      <td>native english teacher english program korea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people development coordinator ryan</td>\n",
       "      <td>people development coordinator ryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>advisory board member celal bayar university</td>\n",
       "      <td>advisory board member celal bayar university</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   1   \n",
       "1   2   \n",
       "2   3   \n",
       "3   4   \n",
       "4   5   \n",
       "\n",
       "                                                                                                  job_title  \\\n",
       "0  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional   \n",
       "1                                                      Native English Teacher at  English Program in Korea    \n",
       "2                                                                     Aspiring Human Resources Professional   \n",
       "3                                                                    People Development Coordinator at Ryan   \n",
       "4                                                           Advisory Board Member at Celal Bayar University   \n",
       "\n",
       "                              location connection  fit  \\\n",
       "0                       Houston, Texas         85  NaN   \n",
       "1                               Kanada      500+   NaN   \n",
       "2  Raleigh-Durham, North Carolina Area         44  NaN   \n",
       "3                        Denton, Texas      500+   NaN   \n",
       "4                       İzmir, Türkiye      500+   NaN   \n",
       "\n",
       "                                                                                   job_title_no_stpw  \\\n",
       "0  2019 c.t. bauer college business graduate (magna cum laude) aspiring human resources professional   \n",
       "1                                                       native english teacher english program korea   \n",
       "2                                                              aspiring human resources professional   \n",
       "3                                                                people development coordinator ryan   \n",
       "4                                                       advisory board member celal bayar university   \n",
       "\n",
       "                                                                           job_title_no_splc  \n",
       "0   ct bauer college business graduate magna cum laude aspiring human resources professional  \n",
       "1                                               native english teacher english program korea  \n",
       "2                                                      aspiring human resources professional  \n",
       "3                                                        people development coordinator ryan  \n",
       "4                                               advisory board member celal bayar university  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing digits and special characters\n",
    "df_nodups['job_title_no_splc'] = df_nodups['job_title_no_stpw'].str.replace(r'[^A-Za-z0-9 ]+', '', regex=True)\n",
    "df_nodups['job_title_no_splc'] = df_nodups['job_title_no_splc'].str.replace(r'\\d+','') \n",
    "df_nodups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "induced-fellow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>job_title_no_stpw</th>\n",
       "      <th>job_title_no_splc</th>\n",
       "      <th>job_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019 c.t. bauer college business graduate (magna cum laude) aspiring human resources professional</td>\n",
       "      <td>ct bauer college business graduate magna cum laude aspiring human resources professional</td>\n",
       "      <td>ct bauer college business graduate magna cum laude aspire human resources professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at  English Program in Korea</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>native english teacher english program korea</td>\n",
       "      <td>native english teacher english program korea</td>\n",
       "      <td>native english teacher english program korea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>aspire human resources professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people development coordinator ryan</td>\n",
       "      <td>people development coordinator ryan</td>\n",
       "      <td>people development coordinator ryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>advisory board member celal bayar university</td>\n",
       "      <td>advisory board member celal bayar university</td>\n",
       "      <td>advisory board member celal bayar university</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   1   \n",
       "1   2   \n",
       "2   3   \n",
       "3   4   \n",
       "4   5   \n",
       "\n",
       "                                                                                                  job_title  \\\n",
       "0  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional   \n",
       "1                                                      Native English Teacher at  English Program in Korea    \n",
       "2                                                                     Aspiring Human Resources Professional   \n",
       "3                                                                    People Development Coordinator at Ryan   \n",
       "4                                                           Advisory Board Member at Celal Bayar University   \n",
       "\n",
       "                              location connection  fit  \\\n",
       "0                       Houston, Texas         85  NaN   \n",
       "1                               Kanada      500+   NaN   \n",
       "2  Raleigh-Durham, North Carolina Area         44  NaN   \n",
       "3                        Denton, Texas      500+   NaN   \n",
       "4                       İzmir, Türkiye      500+   NaN   \n",
       "\n",
       "                                                                                   job_title_no_stpw  \\\n",
       "0  2019 c.t. bauer college business graduate (magna cum laude) aspiring human resources professional   \n",
       "1                                                       native english teacher english program korea   \n",
       "2                                                              aspiring human resources professional   \n",
       "3                                                                people development coordinator ryan   \n",
       "4                                                       advisory board member celal bayar university   \n",
       "\n",
       "                                                                           job_title_no_splc  \\\n",
       "0   ct bauer college business graduate magna cum laude aspiring human resources professional   \n",
       "1                                               native english teacher english program korea   \n",
       "2                                                      aspiring human resources professional   \n",
       "3                                                        people development coordinator ryan   \n",
       "4                                               advisory board member celal bayar university   \n",
       "\n",
       "                                                                           job_lemmatized  \n",
       "0  ct bauer college business graduate magna cum laude aspire human resources professional  \n",
       "1                                            native english teacher english program korea  \n",
       "2                                                     aspire human resources professional  \n",
       "3                                                     people development coordinator ryan  \n",
       "4                                            advisory board member celal bayar university  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lem(words):\n",
    "    return \" \".join([lemmer.lemmatize(word,'v') for word in words.split()])\n",
    "\n",
    "df_nodups['job_lemmatized'] =  df_nodups.job_title_no_splc.apply(lem)\n",
    "\n",
    "df_nodups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "posted-drama",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique features:  175\n",
      "['administration', 'administrative', 'admissions', 'advisory', 'always', 'america', 'an', 'analyst', 'analytics', 'army', 'arts', 'aspire', 'assistant', 'atlanta', 'bachelor', 'bauer', 'bayar', 'beach', 'beneteau', 'biology', 'board', 'brand', 'buckhead', 'business', 'care', 'celal', 'center', 'chapman', 'college', 'communications', 'community', 'compensation', 'conflict', 'coordinator', 'create', 'csr', 'ct', 'cum', 'customer', 'data', 'delphi', 'development', 'director', 'employment', 'endemol', 'energetic', 'energy', 'engage', 'engie', 'engineer', 'english', 'entrylevel', 'environment', 'environmental', 'excellence', 'executive', 'experience', 'ey', 'generalist', 'gi', 'gp', 'graduate', 'groupe', 'guard', 'hardware', 'heil', 'help', 'houston', 'human', 'humber', 'illinois', 'inc', 'inclusive', 'indiana', 'information', 'intelligence', 'intercontinental', 'international', 'internship', 'japan', 'junior', 'kokomo', 'korea', 'lab', 'laude', 'lead', 'leader', 'liberal', 'log', 'long', 'loparex', 'louis', 'love', 'luxottica', 'magna', 'major', 'management', 'managementbenefits', 'manager', 'market', 'may', 'medical', 'member', 'mes', 'national', 'native', 'north', 'nortia', 'of', 'office', 'officer', 'official', 'open', 'opportunities', 'organization', 'paint', 'partner', 'passionate', 'patient', 'payroll', 'people', 'policies', 'portfolio', 'position', 'procedurestalent', 'professional', 'professionals', 'program', 'programmer', 'recruit', 'recruiter', 'relocation', 'representative', 'research', 'resources', 'retail', 'retire', 'rrp', 'ryan', 'schwans', 'science', 'scottmadden', 'seek', 'senior', 'service', 'set', 'shine', 'software', 'sp', 'specialist', 'st', 'staff', 'state', 'student', 'styczynski', 'success', 'svp', 'system', 'systems', 'teacher', 'teamfocused', 'the', 'tobacco', 'travel', 'travelers', 'undergraduate', 'university', 'victoria', 'wellington', 'western', 'westfield', 'within', 'woodlands', 'work', 'world']\n"
     ]
    }
   ],
   "source": [
    "# Convert job_title column into a list\n",
    "job_title_list = list(df_nodups['job_lemmatized'])                    \n",
    "\n",
    "# Vectorize job_title_list\n",
    "vectors = TfidfVectorizer()                                 \n",
    "matrix = vectors.fit_transform(job_title_list)\n",
    "feature_names = vectors.get_feature_names()  \n",
    "print(\"Number of unique features: \", len(feature_names))   \n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ruled-mumbai",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ct': 36,\n",
       " 'bauer': 15,\n",
       " 'college': 28,\n",
       " 'business': 23,\n",
       " 'graduate': 61,\n",
       " 'magna': 94,\n",
       " 'cum': 37,\n",
       " 'laude': 84,\n",
       " 'aspire': 11,\n",
       " 'human': 68,\n",
       " 'resources': 134,\n",
       " 'professional': 125,\n",
       " 'native': 105,\n",
       " 'english': 50,\n",
       " 'teacher': 159,\n",
       " 'program': 127,\n",
       " 'korea': 82,\n",
       " 'people': 120,\n",
       " 'development': 41,\n",
       " 'coordinator': 33,\n",
       " 'ryan': 138,\n",
       " 'advisory': 3,\n",
       " 'board': 20,\n",
       " 'member': 102,\n",
       " 'celal': 25,\n",
       " 'bayar': 16,\n",
       " 'university': 166,\n",
       " 'specialist': 149,\n",
       " 'student': 153,\n",
       " 'humber': 69,\n",
       " 'generalist': 58,\n",
       " 'senior': 143,\n",
       " 'seek': 142,\n",
       " 'information': 74,\n",
       " 'system': 157,\n",
       " 'position': 123,\n",
       " 'chapman': 27,\n",
       " 'svp': 156,\n",
       " 'market': 99,\n",
       " 'communications': 29,\n",
       " 'csr': 35,\n",
       " 'officer': 110,\n",
       " 'engie': 48,\n",
       " 'houston': 67,\n",
       " 'the': 161,\n",
       " 'woodlands': 172,\n",
       " 'energy': 46,\n",
       " 'gp': 60,\n",
       " 'sp': 148,\n",
       " 'intercontinental': 76,\n",
       " 'buckhead': 22,\n",
       " 'atlanta': 13,\n",
       " 'management': 96,\n",
       " 'internship': 78,\n",
       " 'opportunities': 113,\n",
       " 'experience': 56,\n",
       " 'retail': 135,\n",
       " 'manager': 98,\n",
       " 'staff': 151,\n",
       " 'recruit': 129,\n",
       " 'luxottica': 93,\n",
       " 'director': 42,\n",
       " 'north': 106,\n",
       " 'america': 5,\n",
       " 'groupe': 62,\n",
       " 'beneteau': 18,\n",
       " 'retire': 136,\n",
       " 'army': 9,\n",
       " 'national': 104,\n",
       " 'guard': 63,\n",
       " 'recruiter': 130,\n",
       " 'office': 109,\n",
       " 'scottmadden': 141,\n",
       " 'inc': 71,\n",
       " 'major': 95,\n",
       " 'nortia': 107,\n",
       " 'payroll': 119,\n",
       " 'administrative': 1,\n",
       " 'professionals': 126,\n",
       " 'passionate': 117,\n",
       " 'help': 66,\n",
       " 'create': 34,\n",
       " 'inclusive': 72,\n",
       " 'engage': 47,\n",
       " 'work': 173,\n",
       " 'environment': 52,\n",
       " 'conflict': 32,\n",
       " 'policies': 121,\n",
       " 'procedurestalent': 124,\n",
       " 'managementbenefits': 97,\n",
       " 'compensation': 31,\n",
       " 'schwans': 139,\n",
       " 'liberal': 87,\n",
       " 'arts': 10,\n",
       " 'analyst': 7,\n",
       " 'junior': 80,\n",
       " 'mes': 103,\n",
       " 'engineer': 49,\n",
       " 'systems': 158,\n",
       " 'partner': 116,\n",
       " 'heil': 65,\n",
       " 'environmental': 53,\n",
       " 'an': 6,\n",
       " 'energetic': 45,\n",
       " 'teamfocused': 160,\n",
       " 'leader': 86,\n",
       " 'endemol': 44,\n",
       " 'shine': 146,\n",
       " 'world': 174,\n",
       " 'gi': 59,\n",
       " 'software': 147,\n",
       " 'rrp': 137,\n",
       " 'brand': 21,\n",
       " 'portfolio': 122,\n",
       " 'executive': 55,\n",
       " 'japan': 79,\n",
       " 'tobacco': 162,\n",
       " 'international': 77,\n",
       " 'programmer': 128,\n",
       " 'love': 92,\n",
       " 'data': 39,\n",
       " 'organization': 114,\n",
       " 'bachelor': 14,\n",
       " 'science': 140,\n",
       " 'biology': 19,\n",
       " 'victoria': 167,\n",
       " 'wellington': 168,\n",
       " 'ey': 57,\n",
       " 'undergraduate': 165,\n",
       " 'research': 133,\n",
       " 'assistant': 12,\n",
       " 'styczynski': 154,\n",
       " 'lab': 83,\n",
       " 'lead': 85,\n",
       " 'official': 111,\n",
       " 'western': 169,\n",
       " 'illinois': 70,\n",
       " 'employment': 43,\n",
       " 'within': 171,\n",
       " 'customer': 38,\n",
       " 'service': 144,\n",
       " 'patient': 118,\n",
       " 'care': 24,\n",
       " 'admissions': 2,\n",
       " 'representative': 132,\n",
       " 'community': 30,\n",
       " 'medical': 101,\n",
       " 'center': 26,\n",
       " 'long': 89,\n",
       " 'beach': 17,\n",
       " 'open': 112,\n",
       " 'travel': 163,\n",
       " 'relocation': 131,\n",
       " 'westfield': 170,\n",
       " 'state': 152,\n",
       " 'indiana': 73,\n",
       " 'kokomo': 81,\n",
       " 'delphi': 40,\n",
       " 'hardware': 64,\n",
       " 'paint': 115,\n",
       " 'may': 100,\n",
       " 'entrylevel': 51,\n",
       " 'st': 150,\n",
       " 'louis': 91,\n",
       " 'loparex': 90,\n",
       " 'intelligence': 75,\n",
       " 'analytics': 8,\n",
       " 'travelers': 164,\n",
       " 'always': 4,\n",
       " 'set': 145,\n",
       " 'success': 155,\n",
       " 'of': 108,\n",
       " 'administration': 0,\n",
       " 'excellence': 54,\n",
       " 'log': 88}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "looking-estimate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Tfidf vector:  (54, 175)\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.46104593 0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Convert job titles into arrays\n",
    "tfidf_vector = matrix.toarray()                                  \n",
    "print(\"Shape of Tfidf vector: \", tfidf_vector.shape) \n",
    "print(tfidf_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hollywood-musician",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.19276841\n",
      " 0.         0.         0.         0.3511579  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.26173515\n",
      " 0.         0.         0.         0.         0.31815462 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.3511579  0.3511579  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.31815462 0.         0.         0.         0.\n",
      " 0.         0.         0.11589292 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.3511579  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.3511579  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.22015594\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.11589292 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adult-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search query\n",
    "search = \"seeking human resources\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "african-turner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seek human resources\n"
     ]
    }
   ],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "lem_search = \" \".join([lemmer.lemmatize(word,'v') for word in search.split()])\n",
    "print(lem_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "unlimited-minority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of search phrase vector: (1, 175)\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.4319816  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.4319816  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.79169678 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Convert search phrase into a vector\n",
    "sv = vectors.transform([lem_search])                    \n",
    "search_vector = sv.toarray()\n",
    "print(\"Shape of search phrase vector:\", search_vector.shape)\n",
    "print(search_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "instant-somalia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>job_title_no_stpw</th>\n",
       "      <th>job_title_no_splc</th>\n",
       "      <th>job_lemmatized</th>\n",
       "      <th>tfidf_sim_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Seeking Human Resources Position</td>\n",
       "      <td>Las Vegas, Nevada Area</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>seeking human resources position</td>\n",
       "      <td>seeking human resources position</td>\n",
       "      <td>seek human resources position</td>\n",
       "      <td>0.696263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>seeking human resources opportunities</td>\n",
       "      <td>seeking human resources opportunities</td>\n",
       "      <td>seek human resources opportunities</td>\n",
       "      <td>0.673137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73</td>\n",
       "      <td>Aspiring Human Resources Manager, seeking internship in Human Resources.</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspiring human resources manager, seeking internship human resources.</td>\n",
       "      <td>aspiring human resources manager seeking internship human resources</td>\n",
       "      <td>aspire human resources manager seek internship human resources</td>\n",
       "      <td>0.624745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Seeking Human Resources  Human Resources Information System  and Generalist Positions</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>seeking human resources human resources information system generalist positions</td>\n",
       "      <td>seeking human resources human resources information system generalist positions</td>\n",
       "      <td>seek human resources human resources information system generalist position</td>\n",
       "      <td>0.517021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Aspiring Human Resources Management student seeking an internship</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspiring human resources management student seeking internship</td>\n",
       "      <td>aspiring human resources management student seeking internship</td>\n",
       "      <td>aspire human resources management student seek internship</td>\n",
       "      <td>0.459454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  \\\n",
       "98  99   \n",
       "27  28   \n",
       "72  73   \n",
       "9   10   \n",
       "26  27   \n",
       "\n",
       "                                                                                job_title  \\\n",
       "98                                                       Seeking Human Resources Position   \n",
       "27                                                  Seeking Human Resources Opportunities   \n",
       "72               Aspiring Human Resources Manager, seeking internship in Human Resources.   \n",
       "9   Seeking Human Resources  Human Resources Information System  and Generalist Positions   \n",
       "26                      Aspiring Human Resources Management student seeking an internship   \n",
       "\n",
       "                     location connection  fit  \\\n",
       "98     Las Vegas, Nevada Area         48  NaN   \n",
       "27          Chicago, Illinois        390  NaN   \n",
       "72        Houston, Texas Area          7  NaN   \n",
       "9   Greater Philadelphia Area      500+   NaN   \n",
       "26        Houston, Texas Area      500+   NaN   \n",
       "\n",
       "                                                                  job_title_no_stpw  \\\n",
       "98                                                 seeking human resources position   \n",
       "27                                            seeking human resources opportunities   \n",
       "72            aspiring human resources manager, seeking internship human resources.   \n",
       "9   seeking human resources human resources information system generalist positions   \n",
       "26                   aspiring human resources management student seeking internship   \n",
       "\n",
       "                                                                  job_title_no_splc  \\\n",
       "98                                                 seeking human resources position   \n",
       "27                                            seeking human resources opportunities   \n",
       "72              aspiring human resources manager seeking internship human resources   \n",
       "9   seeking human resources human resources information system generalist positions   \n",
       "26                   aspiring human resources management student seeking internship   \n",
       "\n",
       "                                                                 job_lemmatized  \\\n",
       "98                                                seek human resources position   \n",
       "27                                           seek human resources opportunities   \n",
       "72               aspire human resources manager seek internship human resources   \n",
       "9   seek human resources human resources information system generalist position   \n",
       "26                    aspire human resources management student seek internship   \n",
       "\n",
       "    tfidf_sim_score  \n",
       "98         0.696263  \n",
       "27         0.673137  \n",
       "72         0.624745  \n",
       "9          0.517021  \n",
       "26         0.459454  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim = cosine_similarity(tfidf_vector, search_vector)\n",
    "\n",
    "df_nodups['tfidf_sim_score'] = cosine_sim\n",
    "df_nodups.sort_values(by ='tfidf_sim_score', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "durable-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec -h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "functioning-enemy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"1.8.0_312\"; OpenJDK Runtime Environment (build 1.8.0_312-bre_2021_10_21_08_06-b00); OpenJDK 64-Bit Server VM (build 25.312-b00, mixed mode)\n",
      "  Starting server from /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/k8/853v_n2j4mg1fczdrs9bspsh0000gn/T/tmpwzl7lrfl\n",
      "  JVM stdout: /var/folders/k8/853v_n2j4mg1fczdrs9bspsh0000gn/T/tmpwzl7lrfl/h2o_vidyakumar_started_from_python.out\n",
      "  JVM stderr: /var/folders/k8/853v_n2j4mg1fczdrs9bspsh0000gn/T/tmpwzl7lrfl/h2o_vidyakumar_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n",
      "Warning: Your H2O cluster version is too old (4 years, 4 months and 3 days)! Please download and install the latest version from http://h2o.ai/download/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>07 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.16.0.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>4 years, 4 months and 3 days !!!</td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_vidyakumar_yzqh32</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>1.778 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.8.3 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         07 secs\n",
       "H2O cluster version:        3.16.0.2\n",
       "H2O cluster version age:    4 years, 4 months and 3 days !!!\n",
       "H2O cluster name:           H2O_from_python_vidyakumar_yzqh32\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    1.778 Gb\n",
       "H2O cluster total cores:    0\n",
       "H2O cluster allowed cores:  0\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.8.3 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fresh-ownership",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ct',\n",
       "  'bauer',\n",
       "  'college',\n",
       "  'business',\n",
       "  'graduate',\n",
       "  'magna',\n",
       "  'cum',\n",
       "  'laude',\n",
       "  'aspire',\n",
       "  'human',\n",
       "  'resources',\n",
       "  'professional'],\n",
       " ['native', 'english', 'teacher', 'english', 'program', 'korea'],\n",
       " ['aspire', 'human', 'resources', 'professional'],\n",
       " ['people', 'development', 'coordinator', 'ryan'],\n",
       " ['advisory', 'board', 'member', 'celal', 'bayar', 'university']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization of each document\n",
    "tokenized_sent = []\n",
    "lines = df_nodups['job_lemmatized']\n",
    "\n",
    "for line in lines:\n",
    "    # tokenize the text\n",
    "    tokens = word_tokenize(line)\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    tokenized_sent.append(tokens)\n",
    "tokenized_sent[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "sonic-hometown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>C1      </th><th>C2         </th><th>C3         </th><th>C4          </th><th>C5       </th><th>C6         </th><th>C7        </th><th>C8        </th><th>C9      </th><th>C10  </th><th>C11      </th><th>C12         </th><th>C13  </th><th>C14  </th><th>C15  </th><th>C16  </th><th>C17  </th><th>C18  </th><th>C19  </th><th>C20  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>ct      </td><td>bauer      </td><td>college    </td><td>business    </td><td>graduate </td><td>magna      </td><td>cum       </td><td>laude     </td><td>aspire  </td><td>human</td><td>resources</td><td>professional</td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td></tr>\n",
       "<tr><td>native  </td><td>english    </td><td>teacher    </td><td>english     </td><td>program  </td><td>korea      </td><td>          </td><td>          </td><td>        </td><td>     </td><td>         </td><td>            </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td></tr>\n",
       "<tr><td>aspire  </td><td>human      </td><td>resources  </td><td>professional</td><td>         </td><td>           </td><td>          </td><td>          </td><td>        </td><td>     </td><td>         </td><td>            </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td></tr>\n",
       "<tr><td>people  </td><td>development</td><td>coordinator</td><td>ryan        </td><td>         </td><td>           </td><td>          </td><td>          </td><td>        </td><td>     </td><td>         </td><td>            </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td></tr>\n",
       "<tr><td>advisory</td><td>board      </td><td>member     </td><td>celal       </td><td>bayar    </td><td>university </td><td>          </td><td>          </td><td>        </td><td>     </td><td>         </td><td>            </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td></tr>\n",
       "<tr><td>aspire  </td><td>human      </td><td>resources  </td><td>specialist  </td><td>         </td><td>           </td><td>          </td><td>          </td><td>        </td><td>     </td><td>         </td><td>            </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td></tr>\n",
       "<tr><td>student </td><td>humber     </td><td>college    </td><td>aspire      </td><td>human    </td><td>resources  </td><td>generalist</td><td>          </td><td>        </td><td>     </td><td>         </td><td>            </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td></tr>\n",
       "<tr><td>human   </td><td>resources  </td><td>senior     </td><td>specialist  </td><td>         </td><td>           </td><td>          </td><td>          </td><td>        </td><td>     </td><td>         </td><td>            </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td></tr>\n",
       "<tr><td>seek    </td><td>human      </td><td>resources  </td><td>human       </td><td>resources</td><td>information</td><td>system    </td><td>generalist</td><td>position</td><td>     </td><td>         </td><td>            </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td></tr>\n",
       "<tr><td>student </td><td>chapman    </td><td>university </td><td>            </td><td>         </td><td>           </td><td>          </td><td>          </td><td>        </td><td>     </td><td>         </td><td>            </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frame = h2o.H2OFrame(tokenized_sent)\n",
    "#frame\n",
    "words = h2o.H2OFrame(tokenized_sent).ascharacter()\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "noted-survey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h2o.frame.H2OFrame"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "corresponding-people",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Key_Frame__upload_a440e3e698d864a8f744fde97e3341c1.hex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Key_Frame__upload_b1172ee7d2a5d28be5590e9f29184aeb.hex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>py_2_sid_b95d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>w2v.hex</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      key\n",
       "0  Key_Frame__upload_a440e3e698d864a8f744fde97e3341c1.hex\n",
       "1  Key_Frame__upload_b1172ee7d2a5d28be5590e9f29184aeb.hex\n",
       "2                                           py_2_sid_b95d\n",
       "3                                                 w2v.hex"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2o.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "approved-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec Model\n",
    "from h2o.estimators.word2vec import H2OWord2vecEstimator\n",
    "\n",
    "# Pre-trained model available on s3: https://s3.amazonaws.com/tomk/h2o-world/megan/w2v.hex\n",
    "w2v_model = h2o.load_model(\"/Users/vidyakumar/Desktop/python/apziva/w2v.hex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "approximate-bradford",
   "metadata": {},
   "outputs": [
    {
     "ename": "H2OResponseError",
     "evalue": "Server error java.lang.IllegalArgumentException:\n  Error: words frame is expected to have a single string column, got20\n  Request: GET /3/Word2VecTransform\n    params: {'model': 'w2v.hex', 'words_frame': 'py_4_sid_b95d', 'aggregate_method': 'AVERAGE'}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mH2OResponseError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-476ae1582807>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calculate a vector for each review\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#title_vecs = w2v_model.transform(frame, aggregate_method = \"AVERAGE\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mjob_title_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregate_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"AVERAGE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/h2o/model/word_embedding.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, words, aggregate_method)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mapproximate\u001b[0m \u001b[0mreconstruction\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \"\"\"\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET /3/Word2VecTransform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'words_frame'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'aggregate_method'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maggregate_method\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vectors_frame\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/h2o/h2o.py\u001b[0m in \u001b[0;36mapi\u001b[0;34m(endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# type checks are performed in H2OConnection class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0m_check_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mh2oconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                     auth=self._auth, verify=self._verify_ssl_cert, proxies=self._proxies)\n\u001b[1;32m    401\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_end_transaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36m_process_response\u001b[0;34m(response, save_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;31m# Client errors (400 = \"Bad Request\", 404 = \"Not Found\", 412 = \"Precondition Failed\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m404\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m412\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mH2OErrorV3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH2OModelBuilderErrorV3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mH2OResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;31m# Server errors (notably 500 = \"Server Error\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mH2OResponseError\u001b[0m: Server error java.lang.IllegalArgumentException:\n  Error: words frame is expected to have a single string column, got20\n  Request: GET /3/Word2VecTransform\n    params: {'model': 'w2v.hex', 'words_frame': 'py_4_sid_b95d', 'aggregate_method': 'AVERAGE'}\n"
     ]
    }
   ],
   "source": [
    "# Calculate a vector for each title\n",
    "#title_vecs = w2v_model.transform(frame, aggregate_method = \"AVERAGE\")\n",
    "job_title_vec = w2v_model.transform(words, aggregate_method=\"AVERAGE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-solid",
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.word2vec import H2OWord2vecEstimator\n",
    "word_vectors_model = H2OWord2vecEstimator( model_id = \"word_vectors\", vec_size = 100)\n",
    "word_vectors_model.train(training_frame = frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec - trial\n",
    "# Using a pre-trained word2vec model\n",
    "embedding_dim = 300\n",
    "EMBEDDING_FILE = '/Users/vidyakumar/GoogleNews-vectors-negative300.bin'\n",
    "word_vectors = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access vectors for specific words with a keyed lookup:\n",
    "vectort = word_vectors['easy']\n",
    "# see the shape of the vector (300,)\n",
    "vectort.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-intention",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_obj = Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(tokenized_sent)\n",
    "sequences = tokenizer_obj.texts_to_sequences(tokenized_sent)\n",
    "\n",
    "word_index = tokenizer_obj.word_index\n",
    "print(\"unique tokens - \"+str(len(word_index)))\n",
    "vocab_size = len(tokenizer_obj.word_index) + 1\n",
    "print('vocab_size - '+str(vocab_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(tokenized_sent) + 1, embedding_dim))\n",
    "for word, i in tokenized_sent.items():\n",
    "    if word in word2vec_model: \n",
    "        embedding_vector = word2vec_model[word]\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
