{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sapphire-cruise",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "#import tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim.downloader as api\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim import models \n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "#from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "import h2o\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "departmental-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = (\"/Users/vidyakumar/Desktop/python/apziva/potential-talents - Aspiring human resources - seeking human resources.csv\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "associate-excitement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   1   \n",
       "1   2   \n",
       "2   3   \n",
       "3   4   \n",
       "4   5   \n",
       "\n",
       "                                                                                                  job_title  \\\n",
       "0  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional   \n",
       "1                                                                            Native English Teacher at EPIK   \n",
       "2                                                                     Aspiring Human Resources Professional   \n",
       "3                                                                    People Development Coordinator at Ryan   \n",
       "4                                                           Advisory Board Member at Celal Bayar University   \n",
       "\n",
       "                              location connection  fit  \n",
       "0                       Houston, Texas         85  NaN  \n",
       "1                               Kanada      500+   NaN  \n",
       "2  Raleigh-Durham, North Carolina Area         44  NaN  \n",
       "3                        Denton, Texas      500+   NaN  \n",
       "4                       İzmir, Türkiye      500+   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data():\n",
    "    data = pd.read_csv(data_url)\n",
    "    return data\n",
    "\n",
    "data = load_data()\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "educational-proposal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104, 5)\n",
      "(54, 5)\n"
     ]
    }
   ],
   "source": [
    "# If it's the same job description in the same city, for the same job title, we consider it duplicate.\n",
    "print(data.shape)\n",
    "df_nodups = data.drop_duplicates(subset=['job_title', 'location'])\n",
    "print(df_nodups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cardiac-photographer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "job_title      0\n",
       "location       0\n",
       "connection     0\n",
       "fit           54\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodups.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "assigned-drawing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 54 entries, 0 to 103\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   id          54 non-null     int64  \n",
      " 1   job_title   54 non-null     object \n",
      " 2   location    54 non-null     object \n",
      " 3   connection  54 non-null     object \n",
      " 4   fit         0 non-null      float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 2.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_nodups.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "documentary-unemployment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>job_title_no_stpw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019 c.t. bauer college business graduate (magna cum laude) aspiring human resources professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at  English Program in Korea</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>native english teacher english program korea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people development coordinator ryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>advisory board member celal bayar university</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspiring human resources specialist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Student at Humber College and Aspiring Human Resources Generalist</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>student humber college aspiring human resources generalist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Human Resources  Senior Specialist</td>\n",
       "      <td>San Francisco Bay Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>human resources senior specialist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Seeking Human Resources  Human Resources Information System  and Generalist Positions</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>seeking human resources human resources information system generalist positions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Student at Chapman University</td>\n",
       "      <td>Lake Forest, California</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>student chapman university</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  \\\n",
       "0    1   \n",
       "1    2   \n",
       "2    3   \n",
       "3    4   \n",
       "4    5   \n",
       "5    6   \n",
       "6    7   \n",
       "7    8   \n",
       "9   10   \n",
       "10  11   \n",
       "\n",
       "                                                                                                   job_title  \\\n",
       "0   2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional   \n",
       "1                                                       Native English Teacher at  English Program in Korea    \n",
       "2                                                                      Aspiring Human Resources Professional   \n",
       "3                                                                     People Development Coordinator at Ryan   \n",
       "4                                                            Advisory Board Member at Celal Bayar University   \n",
       "5                                                                        Aspiring Human Resources Specialist   \n",
       "6                                          Student at Humber College and Aspiring Human Resources Generalist   \n",
       "7                                                                         Human Resources  Senior Specialist   \n",
       "9                      Seeking Human Resources  Human Resources Information System  and Generalist Positions   \n",
       "10                                                                             Student at Chapman University   \n",
       "\n",
       "                               location connection  fit  \\\n",
       "0                        Houston, Texas         85  NaN   \n",
       "1                                Kanada      500+   NaN   \n",
       "2   Raleigh-Durham, North Carolina Area         44  NaN   \n",
       "3                         Denton, Texas      500+   NaN   \n",
       "4                        İzmir, Türkiye      500+   NaN   \n",
       "5            Greater New York City Area          1  NaN   \n",
       "6                                Kanada         61  NaN   \n",
       "7                San Francisco Bay Area      500+   NaN   \n",
       "9             Greater Philadelphia Area      500+   NaN   \n",
       "10              Lake Forest, California          2  NaN   \n",
       "\n",
       "                                                                                    job_title_no_stpw  \n",
       "0   2019 c.t. bauer college business graduate (magna cum laude) aspiring human resources professional  \n",
       "1                                                        native english teacher english program korea  \n",
       "2                                                               aspiring human resources professional  \n",
       "3                                                                 people development coordinator ryan  \n",
       "4                                                        advisory board member celal bayar university  \n",
       "5                                                                 aspiring human resources specialist  \n",
       "6                                          student humber college aspiring human resources generalist  \n",
       "7                                                                   human resources senior specialist  \n",
       "9                     seeking human resources human resources information system generalist positions  \n",
       "10                                                                         student chapman university  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace acronymns\n",
    "df_nodups['job_title'] = df_nodups['job_title'].str.replace(\"HRIS\", \" Human Resources Information System \")\n",
    "df_nodups['job_title'] = df_nodups['job_title'].str.replace(\"HR\", \" Human Resources \")\n",
    "df_nodups['job_title'] = df_nodups['job_title'].str.replace(\"EPIK\", \" English Program in Korea \")\n",
    "df_nodups['job_title'] = df_nodups['job_title'].str.replace(\"JTI\", \" Japan Tobacco International \")\n",
    "\n",
    "#removing stopwords and making it all lowercase\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df_nodups['job_title_no_stpw'] = df_nodups['job_title'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "df_nodups['job_title_no_stpw'] = df_nodups['job_title_no_stpw'].str.lower()\n",
    "df_nodups.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "approximate-timing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>job_title_no_stpw</th>\n",
       "      <th>job_title_no_splc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019 c.t. bauer college business graduate (magna cum laude) aspiring human resources professional</td>\n",
       "      <td>ct bauer college business graduate magna cum laude aspiring human resources professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at  English Program in Korea</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>native english teacher english program korea</td>\n",
       "      <td>native english teacher english program korea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people development coordinator ryan</td>\n",
       "      <td>people development coordinator ryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>advisory board member celal bayar university</td>\n",
       "      <td>advisory board member celal bayar university</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   1   \n",
       "1   2   \n",
       "2   3   \n",
       "3   4   \n",
       "4   5   \n",
       "\n",
       "                                                                                                  job_title  \\\n",
       "0  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional   \n",
       "1                                                      Native English Teacher at  English Program in Korea    \n",
       "2                                                                     Aspiring Human Resources Professional   \n",
       "3                                                                    People Development Coordinator at Ryan   \n",
       "4                                                           Advisory Board Member at Celal Bayar University   \n",
       "\n",
       "                              location connection  fit  \\\n",
       "0                       Houston, Texas         85  NaN   \n",
       "1                               Kanada      500+   NaN   \n",
       "2  Raleigh-Durham, North Carolina Area         44  NaN   \n",
       "3                        Denton, Texas      500+   NaN   \n",
       "4                       İzmir, Türkiye      500+   NaN   \n",
       "\n",
       "                                                                                   job_title_no_stpw  \\\n",
       "0  2019 c.t. bauer college business graduate (magna cum laude) aspiring human resources professional   \n",
       "1                                                       native english teacher english program korea   \n",
       "2                                                              aspiring human resources professional   \n",
       "3                                                                people development coordinator ryan   \n",
       "4                                                       advisory board member celal bayar university   \n",
       "\n",
       "                                                                           job_title_no_splc  \n",
       "0   ct bauer college business graduate magna cum laude aspiring human resources professional  \n",
       "1                                               native english teacher english program korea  \n",
       "2                                                      aspiring human resources professional  \n",
       "3                                                        people development coordinator ryan  \n",
       "4                                               advisory board member celal bayar university  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing digits and special characters\n",
    "df_nodups['job_title_no_splc'] = df_nodups['job_title_no_stpw'].str.replace(r'[^A-Za-z0-9 ]+', '', regex=True)\n",
    "df_nodups['job_title_no_splc'] = df_nodups['job_title_no_splc'].str.replace(r'\\d+','') \n",
    "df_nodups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "induced-fellow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>job_title_no_stpw</th>\n",
       "      <th>job_title_no_splc</th>\n",
       "      <th>job_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019 c.t. bauer college business graduate (magna cum laude) aspiring human resources professional</td>\n",
       "      <td>ct bauer college business graduate magna cum laude aspiring human resources professional</td>\n",
       "      <td>ct bauer college business graduate magna cum laude aspire human resources professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at  English Program in Korea</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>native english teacher english program korea</td>\n",
       "      <td>native english teacher english program korea</td>\n",
       "      <td>native english teacher english program korea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>aspire human resources professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people development coordinator ryan</td>\n",
       "      <td>people development coordinator ryan</td>\n",
       "      <td>people development coordinator ryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>advisory board member celal bayar university</td>\n",
       "      <td>advisory board member celal bayar university</td>\n",
       "      <td>advisory board member celal bayar university</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   1   \n",
       "1   2   \n",
       "2   3   \n",
       "3   4   \n",
       "4   5   \n",
       "\n",
       "                                                                                                  job_title  \\\n",
       "0  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional   \n",
       "1                                                      Native English Teacher at  English Program in Korea    \n",
       "2                                                                     Aspiring Human Resources Professional   \n",
       "3                                                                    People Development Coordinator at Ryan   \n",
       "4                                                           Advisory Board Member at Celal Bayar University   \n",
       "\n",
       "                              location connection  fit  \\\n",
       "0                       Houston, Texas         85  NaN   \n",
       "1                               Kanada      500+   NaN   \n",
       "2  Raleigh-Durham, North Carolina Area         44  NaN   \n",
       "3                        Denton, Texas      500+   NaN   \n",
       "4                       İzmir, Türkiye      500+   NaN   \n",
       "\n",
       "                                                                                   job_title_no_stpw  \\\n",
       "0  2019 c.t. bauer college business graduate (magna cum laude) aspiring human resources professional   \n",
       "1                                                       native english teacher english program korea   \n",
       "2                                                              aspiring human resources professional   \n",
       "3                                                                people development coordinator ryan   \n",
       "4                                                       advisory board member celal bayar university   \n",
       "\n",
       "                                                                           job_title_no_splc  \\\n",
       "0   ct bauer college business graduate magna cum laude aspiring human resources professional   \n",
       "1                                               native english teacher english program korea   \n",
       "2                                                      aspiring human resources professional   \n",
       "3                                                        people development coordinator ryan   \n",
       "4                                               advisory board member celal bayar university   \n",
       "\n",
       "                                                                           job_lemmatized  \n",
       "0  ct bauer college business graduate magna cum laude aspire human resources professional  \n",
       "1                                            native english teacher english program korea  \n",
       "2                                                     aspire human resources professional  \n",
       "3                                                     people development coordinator ryan  \n",
       "4                                            advisory board member celal bayar university  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lem(words):\n",
    "    return \" \".join([lemmer.lemmatize(word,'v') for word in words.split()])\n",
    "\n",
    "df_nodups['job_lemmatized'] =  df_nodups.job_title_no_splc.apply(lem)\n",
    "\n",
    "df_nodups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "posted-drama",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique features:  175\n",
      "['administration', 'administrative', 'admissions', 'advisory', 'always', 'america', 'an', 'analyst', 'analytics', 'army', 'arts', 'aspire', 'assistant', 'atlanta', 'bachelor', 'bauer', 'bayar', 'beach', 'beneteau', 'biology', 'board', 'brand', 'buckhead', 'business', 'care', 'celal', 'center', 'chapman', 'college', 'communications', 'community', 'compensation', 'conflict', 'coordinator', 'create', 'csr', 'ct', 'cum', 'customer', 'data', 'delphi', 'development', 'director', 'employment', 'endemol', 'energetic', 'energy', 'engage', 'engie', 'engineer', 'english', 'entrylevel', 'environment', 'environmental', 'excellence', 'executive', 'experience', 'ey', 'generalist', 'gi', 'gp', 'graduate', 'groupe', 'guard', 'hardware', 'heil', 'help', 'houston', 'human', 'humber', 'illinois', 'inc', 'inclusive', 'indiana', 'information', 'intelligence', 'intercontinental', 'international', 'internship', 'japan', 'junior', 'kokomo', 'korea', 'lab', 'laude', 'lead', 'leader', 'liberal', 'log', 'long', 'loparex', 'louis', 'love', 'luxottica', 'magna', 'major', 'management', 'managementbenefits', 'manager', 'market', 'may', 'medical', 'member', 'mes', 'national', 'native', 'north', 'nortia', 'of', 'office', 'officer', 'official', 'open', 'opportunities', 'organization', 'paint', 'partner', 'passionate', 'patient', 'payroll', 'people', 'policies', 'portfolio', 'position', 'procedurestalent', 'professional', 'professionals', 'program', 'programmer', 'recruit', 'recruiter', 'relocation', 'representative', 'research', 'resources', 'retail', 'retire', 'rrp', 'ryan', 'schwans', 'science', 'scottmadden', 'seek', 'senior', 'service', 'set', 'shine', 'software', 'sp', 'specialist', 'st', 'staff', 'state', 'student', 'styczynski', 'success', 'svp', 'system', 'systems', 'teacher', 'teamfocused', 'the', 'tobacco', 'travel', 'travelers', 'undergraduate', 'university', 'victoria', 'wellington', 'western', 'westfield', 'within', 'woodlands', 'work', 'world']\n"
     ]
    }
   ],
   "source": [
    "# Convert job_title column into a list\n",
    "job_title_list = list(df_nodups['job_lemmatized'])                    \n",
    "\n",
    "# Vectorize job_title_list\n",
    "vectors = TfidfVectorizer()                                 \n",
    "matrix = vectors.fit_transform(job_title_list)\n",
    "feature_names = vectors.get_feature_names()  \n",
    "print(\"Number of unique features: \", len(feature_names))   \n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "allied-switzerland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ct': 36,\n",
       " 'bauer': 15,\n",
       " 'college': 28,\n",
       " 'business': 23,\n",
       " 'graduate': 61,\n",
       " 'magna': 94,\n",
       " 'cum': 37,\n",
       " 'laude': 84,\n",
       " 'aspire': 11,\n",
       " 'human': 68,\n",
       " 'resources': 134,\n",
       " 'professional': 125,\n",
       " 'native': 105,\n",
       " 'english': 50,\n",
       " 'teacher': 159,\n",
       " 'program': 127,\n",
       " 'korea': 82,\n",
       " 'people': 120,\n",
       " 'development': 41,\n",
       " 'coordinator': 33,\n",
       " 'ryan': 138,\n",
       " 'advisory': 3,\n",
       " 'board': 20,\n",
       " 'member': 102,\n",
       " 'celal': 25,\n",
       " 'bayar': 16,\n",
       " 'university': 166,\n",
       " 'specialist': 149,\n",
       " 'student': 153,\n",
       " 'humber': 69,\n",
       " 'generalist': 58,\n",
       " 'senior': 143,\n",
       " 'seek': 142,\n",
       " 'information': 74,\n",
       " 'system': 157,\n",
       " 'position': 123,\n",
       " 'chapman': 27,\n",
       " 'svp': 156,\n",
       " 'market': 99,\n",
       " 'communications': 29,\n",
       " 'csr': 35,\n",
       " 'officer': 110,\n",
       " 'engie': 48,\n",
       " 'houston': 67,\n",
       " 'the': 161,\n",
       " 'woodlands': 172,\n",
       " 'energy': 46,\n",
       " 'gp': 60,\n",
       " 'sp': 148,\n",
       " 'intercontinental': 76,\n",
       " 'buckhead': 22,\n",
       " 'atlanta': 13,\n",
       " 'management': 96,\n",
       " 'internship': 78,\n",
       " 'opportunities': 113,\n",
       " 'experience': 56,\n",
       " 'retail': 135,\n",
       " 'manager': 98,\n",
       " 'staff': 151,\n",
       " 'recruit': 129,\n",
       " 'luxottica': 93,\n",
       " 'director': 42,\n",
       " 'north': 106,\n",
       " 'america': 5,\n",
       " 'groupe': 62,\n",
       " 'beneteau': 18,\n",
       " 'retire': 136,\n",
       " 'army': 9,\n",
       " 'national': 104,\n",
       " 'guard': 63,\n",
       " 'recruiter': 130,\n",
       " 'office': 109,\n",
       " 'scottmadden': 141,\n",
       " 'inc': 71,\n",
       " 'major': 95,\n",
       " 'nortia': 107,\n",
       " 'payroll': 119,\n",
       " 'administrative': 1,\n",
       " 'professionals': 126,\n",
       " 'passionate': 117,\n",
       " 'help': 66,\n",
       " 'create': 34,\n",
       " 'inclusive': 72,\n",
       " 'engage': 47,\n",
       " 'work': 173,\n",
       " 'environment': 52,\n",
       " 'conflict': 32,\n",
       " 'policies': 121,\n",
       " 'procedurestalent': 124,\n",
       " 'managementbenefits': 97,\n",
       " 'compensation': 31,\n",
       " 'schwans': 139,\n",
       " 'liberal': 87,\n",
       " 'arts': 10,\n",
       " 'analyst': 7,\n",
       " 'junior': 80,\n",
       " 'mes': 103,\n",
       " 'engineer': 49,\n",
       " 'systems': 158,\n",
       " 'partner': 116,\n",
       " 'heil': 65,\n",
       " 'environmental': 53,\n",
       " 'an': 6,\n",
       " 'energetic': 45,\n",
       " 'teamfocused': 160,\n",
       " 'leader': 86,\n",
       " 'endemol': 44,\n",
       " 'shine': 146,\n",
       " 'world': 174,\n",
       " 'gi': 59,\n",
       " 'software': 147,\n",
       " 'rrp': 137,\n",
       " 'brand': 21,\n",
       " 'portfolio': 122,\n",
       " 'executive': 55,\n",
       " 'japan': 79,\n",
       " 'tobacco': 162,\n",
       " 'international': 77,\n",
       " 'programmer': 128,\n",
       " 'love': 92,\n",
       " 'data': 39,\n",
       " 'organization': 114,\n",
       " 'bachelor': 14,\n",
       " 'science': 140,\n",
       " 'biology': 19,\n",
       " 'victoria': 167,\n",
       " 'wellington': 168,\n",
       " 'ey': 57,\n",
       " 'undergraduate': 165,\n",
       " 'research': 133,\n",
       " 'assistant': 12,\n",
       " 'styczynski': 154,\n",
       " 'lab': 83,\n",
       " 'lead': 85,\n",
       " 'official': 111,\n",
       " 'western': 169,\n",
       " 'illinois': 70,\n",
       " 'employment': 43,\n",
       " 'within': 171,\n",
       " 'customer': 38,\n",
       " 'service': 144,\n",
       " 'patient': 118,\n",
       " 'care': 24,\n",
       " 'admissions': 2,\n",
       " 'representative': 132,\n",
       " 'community': 30,\n",
       " 'medical': 101,\n",
       " 'center': 26,\n",
       " 'long': 89,\n",
       " 'beach': 17,\n",
       " 'open': 112,\n",
       " 'travel': 163,\n",
       " 'relocation': 131,\n",
       " 'westfield': 170,\n",
       " 'state': 152,\n",
       " 'indiana': 73,\n",
       " 'kokomo': 81,\n",
       " 'delphi': 40,\n",
       " 'hardware': 64,\n",
       " 'paint': 115,\n",
       " 'may': 100,\n",
       " 'entrylevel': 51,\n",
       " 'st': 150,\n",
       " 'louis': 91,\n",
       " 'loparex': 90,\n",
       " 'intelligence': 75,\n",
       " 'analytics': 8,\n",
       " 'travelers': 164,\n",
       " 'always': 4,\n",
       " 'set': 145,\n",
       " 'success': 155,\n",
       " 'of': 108,\n",
       " 'administration': 0,\n",
       " 'excellence': 54,\n",
       " 'log': 88}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "looking-estimate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Tfidf vector:  (54, 175)\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.46104593 0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Convert job titles into arrays\n",
    "tfidf_vector = matrix.toarray()                                  \n",
    "print(\"Shape of Tfidf vector: \", tfidf_vector.shape) \n",
    "print(tfidf_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "logical-rogers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.19276841\n",
      " 0.         0.         0.         0.3511579  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.26173515\n",
      " 0.         0.         0.         0.         0.31815462 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.3511579  0.3511579  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.31815462 0.         0.         0.         0.\n",
      " 0.         0.         0.11589292 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.3511579  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.3511579  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.22015594\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.11589292 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adult-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search query\n",
    "search = \"seeking human resources\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "center-causing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seek human resources\n"
     ]
    }
   ],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "lem_search = \" \".join([lemmer.lemmatize(word,'v') for word in search.split()])\n",
    "print(lem_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "pretty-amazon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of search phrase vector: (1, 175)\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.4319816  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.4319816  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.79169678 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Convert search phrase into a vector\n",
    "sv = vectors.transform([lem_search])                    \n",
    "search_vector = sv.toarray()\n",
    "print(\"Shape of search phrase vector:\", search_vector.shape)\n",
    "print(search_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sound-gardening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>job_title_no_stpw</th>\n",
       "      <th>job_title_no_splc</th>\n",
       "      <th>job_lemmatized</th>\n",
       "      <th>tfidf_sim_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Seeking Human Resources Position</td>\n",
       "      <td>Las Vegas, Nevada Area</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>seeking human resources position</td>\n",
       "      <td>seeking human resources position</td>\n",
       "      <td>seek human resources position</td>\n",
       "      <td>0.696263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>seeking human resources opportunities</td>\n",
       "      <td>seeking human resources opportunities</td>\n",
       "      <td>seek human resources opportunities</td>\n",
       "      <td>0.673137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73</td>\n",
       "      <td>Aspiring Human Resources Manager, seeking internship in Human Resources.</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspiring human resources manager, seeking internship human resources.</td>\n",
       "      <td>aspiring human resources manager seeking internship human resources</td>\n",
       "      <td>aspire human resources manager seek internship human resources</td>\n",
       "      <td>0.624745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Seeking Human Resources  Human Resources Information System  and Generalist Positions</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>seeking human resources human resources information system generalist positions</td>\n",
       "      <td>seeking human resources human resources information system generalist positions</td>\n",
       "      <td>seek human resources human resources information system generalist position</td>\n",
       "      <td>0.517021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Aspiring Human Resources Management student seeking an internship</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspiring human resources management student seeking internship</td>\n",
       "      <td>aspiring human resources management student seeking internship</td>\n",
       "      <td>aspire human resources management student seek internship</td>\n",
       "      <td>0.459454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  \\\n",
       "98  99   \n",
       "27  28   \n",
       "72  73   \n",
       "9   10   \n",
       "26  27   \n",
       "\n",
       "                                                                                job_title  \\\n",
       "98                                                       Seeking Human Resources Position   \n",
       "27                                                  Seeking Human Resources Opportunities   \n",
       "72               Aspiring Human Resources Manager, seeking internship in Human Resources.   \n",
       "9   Seeking Human Resources  Human Resources Information System  and Generalist Positions   \n",
       "26                      Aspiring Human Resources Management student seeking an internship   \n",
       "\n",
       "                     location connection  fit  \\\n",
       "98     Las Vegas, Nevada Area         48  NaN   \n",
       "27          Chicago, Illinois        390  NaN   \n",
       "72        Houston, Texas Area          7  NaN   \n",
       "9   Greater Philadelphia Area      500+   NaN   \n",
       "26        Houston, Texas Area      500+   NaN   \n",
       "\n",
       "                                                                  job_title_no_stpw  \\\n",
       "98                                                 seeking human resources position   \n",
       "27                                            seeking human resources opportunities   \n",
       "72            aspiring human resources manager, seeking internship human resources.   \n",
       "9   seeking human resources human resources information system generalist positions   \n",
       "26                   aspiring human resources management student seeking internship   \n",
       "\n",
       "                                                                  job_title_no_splc  \\\n",
       "98                                                 seeking human resources position   \n",
       "27                                            seeking human resources opportunities   \n",
       "72              aspiring human resources manager seeking internship human resources   \n",
       "9   seeking human resources human resources information system generalist positions   \n",
       "26                   aspiring human resources management student seeking internship   \n",
       "\n",
       "                                                                 job_lemmatized  \\\n",
       "98                                                seek human resources position   \n",
       "27                                           seek human resources opportunities   \n",
       "72               aspire human resources manager seek internship human resources   \n",
       "9   seek human resources human resources information system generalist position   \n",
       "26                    aspire human resources management student seek internship   \n",
       "\n",
       "    tfidf_sim_score  \n",
       "98         0.696263  \n",
       "27         0.673137  \n",
       "72         0.624745  \n",
       "9          0.517021  \n",
       "26         0.459454  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim = cosine_similarity(tfidf_vector, search_vector)\n",
    "\n",
    "df_nodups['tfidf_sim_score'] = cosine_sim\n",
    "df_nodups.sort_values(by ='tfidf_sim_score', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-novel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec -h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adapted-recruitment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"1.8.0_312\"; OpenJDK Runtime Environment (build 1.8.0_312-bre_2021_10_21_08_06-b00); OpenJDK 64-Bit Server VM (build 25.312-b00, mixed mode)\n",
      "  Starting server from /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/k8/853v_n2j4mg1fczdrs9bspsh0000gn/T/tmp4tphecc5\n",
      "  JVM stdout: /var/folders/k8/853v_n2j4mg1fczdrs9bspsh0000gn/T/tmp4tphecc5/h2o_vidyakumar_started_from_python.out\n",
      "  JVM stderr: /var/folders/k8/853v_n2j4mg1fczdrs9bspsh0000gn/T/tmp4tphecc5/h2o_vidyakumar_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>13 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/Toronto</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.36.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>2 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_vidyakumar_h09rdg</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1.778 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.3 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------\n",
       "H2O_cluster_uptime:         13 secs\n",
       "H2O_cluster_timezone:       America/Toronto\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.36.0.4\n",
       "H2O_cluster_version_age:    2 days\n",
       "H2O_cluster_name:           H2O_from_python_vidyakumar_h09rdg\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1.778 Gb\n",
       "H2O_cluster_total_cores:    0\n",
       "H2O_cluster_allowed_cores:  0\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.8.3 final\n",
       "--------------------------  ---------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ahead-florence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ct',\n",
       "  'bauer',\n",
       "  'college',\n",
       "  'business',\n",
       "  'graduate',\n",
       "  'magna',\n",
       "  'cum',\n",
       "  'laude',\n",
       "  'aspire',\n",
       "  'human',\n",
       "  'resources',\n",
       "  'professional'],\n",
       " ['native', 'english', 'teacher', 'english', 'program', 'korea'],\n",
       " ['aspire', 'human', 'resources', 'professional'],\n",
       " ['people', 'development', 'coordinator', 'ryan'],\n",
       " ['advisory', 'board', 'member', 'celal', 'bayar', 'university']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization of each document\n",
    "tokenized_sent = []\n",
    "lines = df_nodups['job_lemmatized']\n",
    "\n",
    "for line in lines:\n",
    "    # tokenize the text\n",
    "    tokens = word_tokenize(line)\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    tokenized_sent.append(tokens)\n",
    "tokenized_sent[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "right-nation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>C1      </th><th>C2         </th><th>C3         </th><th>C4          </th><th>C5       </th><th>C6         </th><th>C7        </th><th>C8        </th><th>C9      </th><th>C10  </th><th>C11      </th><th>C12         </th><th>C13  </th><th>C14  </th><th>C15  </th><th>C16  </th><th>C17  </th><th>C18  </th><th>C19  </th><th>C20  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>ct      </td><td>bauer      </td><td>college    </td><td>business    </td><td>graduate </td><td>magna      </td><td>cum       </td><td>laude     </td><td>aspire  </td><td>human</td><td>resources</td><td>professional</td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td></tr>\n",
       "<tr><td>native  </td><td>english    </td><td>teacher    </td><td>english     </td><td>program  </td><td>korea      </td><td>          </td><td>          </td><td>        </td><td>     </td><td>         </td><td>            </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td></tr>\n",
       "<tr><td>aspire  </td><td>human      </td><td>resources  </td><td>professional</td><td>         </td><td>           </td><td>          </td><td>          </td><td>        </td><td>     </td><td>         </td><td>            </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td></tr>\n",
       "<tr><td>people  </td><td>development</td><td>coordinator</td><td>ryan        </td><td>         </td><td>           </td><td>          </td><td>          </td><td>        </td><td>     </td><td>         </td><td>            </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td></tr>\n",
       "<tr><td>advisory</td><td>board      </td><td>member     </td><td>celal       </td><td>bayar    </td><td>university </td><td>          </td><td>          </td><td>        </td><td>     </td><td>         </td><td>            </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td></tr>\n",
       "<tr><td>aspire  </td><td>human      </td><td>resources  </td><td>specialist  </td><td>         </td><td>           </td><td>          </td><td>          </td><td>        </td><td>     </td><td>         </td><td>            </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td></tr>\n",
       "<tr><td>student </td><td>humber     </td><td>college    </td><td>aspire      </td><td>human    </td><td>resources  </td><td>generalist</td><td>          </td><td>        </td><td>     </td><td>         </td><td>            </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td></tr>\n",
       "<tr><td>human   </td><td>resources  </td><td>senior     </td><td>specialist  </td><td>         </td><td>           </td><td>          </td><td>          </td><td>        </td><td>     </td><td>         </td><td>            </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td></tr>\n",
       "<tr><td>seek    </td><td>human      </td><td>resources  </td><td>human       </td><td>resources</td><td>information</td><td>system    </td><td>generalist</td><td>position</td><td>     </td><td>         </td><td>            </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td></tr>\n",
       "<tr><td>student </td><td>chapman    </td><td>university </td><td>            </td><td>         </td><td>           </td><td>          </td><td>          </td><td>        </td><td>     </td><td>         </td><td>            </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = h2o.H2OFrame(tokenized_sent)\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "functional-nicholas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h2o.frame.H2OFrame"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "simplified-butter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Key_Frame__upload_b05cc6655ebae6fad56abe059f544d16.hex</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      key\n",
       "0  Key_Frame__upload_b05cc6655ebae6fad56abe059f544d16.hex"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2o.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "atmospheric-vessel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a pre-trained word2vec model\n",
    "embedding_dim = 300\n",
    "EMBEDDING_FILE = '/Users/vidyakumar/GoogleNews-vectors-negative300.bin'\n",
    "word_vectors = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "genuine-culture",
   "metadata": {},
   "outputs": [
    {
     "ename": "H2OResponseError",
     "evalue": "ModelBuilderErrorV3  (water.exceptions.H2OModelBuilderIllegalArgumentException):\n    timestamp = 1648859996532\n    error_url = '/3/ModelBuilders/word2vec'\n    msg = 'Illegal argument(s) for Word2Vec model: word_vectors.  Details: ERRR on field: _train: The first column of the training input frame has to be column of Strings.'\n    dev_msg = 'Illegal argument(s) for Word2Vec model: word_vectors.  Details: ERRR on field: _train: The first column of the training input frame has to be column of Strings.'\n    http_status = 412\n    values = {'messages': [{'_log_level': 5, '_field_name': '_keep_cross_validation_models', '_message': 'Only for cross-validation.'}, {'_log_level': 5, '_field_name': '_keep_cross_validation_predictions', '_message': 'Only for cross-validation.'}, {'_log_level': 5, '_field_name': '_keep_cross_validation_fold_assignment', '_message': 'Only for cross-validation.'}, {'_log_level': 5, '_field_name': '_fold_assignment', '_message': 'Only for cross-validation.'}, {'_log_level': 5, '_field_name': '_tweedie_power', '_message': 'Only for Tweedie Distribution.'}, {'_log_level': 5, '_field_name': '_response_column', '_message': 'Ignored for unsupervised methods.'}, {'_log_level': 5, '_field_name': '_balance_classes', '_message': 'Ignored for unsupervised methods.'}, {'_log_level': 5, '_field_name': '_class_sampling_factors', '_message': 'Ignored for unsupervised methods.'}, {'_log_level': 5, '_field_name': '_max_after_balance_size', '_message': 'Ignored for unsupervised methods.'}, {'_log_level': 5, '_field_name': '_max_confusion_matrix_size', '_message': 'Ignored for unsupervised methods.'}, {'_log_level': 1, '_field_name': '_train', '_message': 'The first column of the training input frame has to be column of Strings.'}], 'algo': 'Word2Vec', 'parameters': {'_train': {'name': 'Key_Frame__upload_b05cc6655ebae6fad56abe059f544d16.hex', 'type': 'Key'}, '_valid': None, '_nfolds': 0, '_keep_cross_validation_models': True, '_keep_cross_validation_predictions': False, '_keep_cross_validation_predictions_precision': -1, '_keep_cross_validation_fold_assignment': False, '_parallelize_cross_validation': True, '_auto_rebalance': True, '_preprocessors': None, '_seed': -1, '_fold_assignment': 'AUTO', '_categorical_encoding': 'AUTO', '_max_categorical_levels': 10, '_distribution': 'AUTO', '_tweedie_power': 1.5, '_quantile_alpha': 0.5, '_huber_alpha': 0.9, '_ignored_columns': None, '_ignore_const_cols': True, '_weights_column': None, '_offset_column': None, '_fold_column': None, '_treatment_column': None, '_check_constant_response': True, '_is_cv_model': False, '_cv_fold': -1, '_score_each_iteration': False, '_max_runtime_secs': 0.0, '_stopping_rounds': 0, '_stopping_metric': 'AUTO', '_stopping_tolerance': 0.001, '_response_column': None, '_balance_classes': False, '_max_after_balance_size': 5.0, '_class_sampling_factors': None, '_max_confusion_matrix_size': 20, '_checkpoint': None, '_pretrained_autoencoder': None, '_custom_metric_func': None, '_custom_distribution_func': None, '_export_checkpoints_dir': None, '_gainslift_bins': -1, '_auc_type': 'AUTO', '_auuc_type': 'AUTO', '_auuc_nbins': -1, '_word_model': 'SkipGram', '_norm_model': 'HSM', '_min_word_freq': 5, '_vec_size': 100, '_window_size': 5, '_epochs': 5, '_init_learning_rate': 0.025, '_sent_sample_rate': 0.001, '_pre_trained': None}, 'error_count': 2}\n    exception_msg = 'Illegal argument(s) for Word2Vec model: word_vectors.  Details: ERRR on field: _train: The first column of the training input frame has to be column of Strings.'\n    stacktrace = ['water.exceptions.H2OModelBuilderIllegalArgumentException: Illegal argument(s) for Word2Vec model: word_vectors.  Details: ERRR on field: _train: The first column of the training input frame has to be column of Strings.\\n', '    water.exceptions.H2OModelBuilderIllegalArgumentException.makeFromBuilder(H2OModelBuilderIllegalArgumentException.java:19)', '    hex.ModelBuilder.trainModelOnH2ONode(ModelBuilder.java:334)', '    water.api.ModelBuilderHandler.handle(ModelBuilderHandler.java:51)', '    water.api.ModelBuilderHandler.handle(ModelBuilderHandler.java:16)', '    water.api.RequestServer.serve(RequestServer.java:470)', '    water.api.RequestServer.doGeneric(RequestServer.java:301)', '    water.api.RequestServer.doPost(RequestServer.java:227)', '    javax.servlet.http.HttpServlet.service(HttpServlet.java:707)', '    javax.servlet.http.HttpServlet.service(HttpServlet.java:790)', '    org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:865)', '    org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:535)', '    org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)', '    org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1317)', '    org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)', '    org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)', '    org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)', '    org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1219)', '    org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)', '    org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)', '    org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)', '    water.webserver.jetty9.Jetty9ServerAdapter$LoginHandler.handle(Jetty9ServerAdapter.java:130)', '    org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)', '    org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)', '    org.eclipse.jetty.server.Server.handle(Server.java:531)', '    org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:352)', '    org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)', '    org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:281)', '    org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:102)', '    org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)', '    org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)', '    org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)', '    org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)', '    org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)', '    org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)', '    org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:762)', '    org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:680)', '    java.lang.Thread.run(Thread.java:748)']\n    parameters = {'__meta': {'schema_version': 3, 'schema_name': 'Word2VecParametersV3', 'schema_type': 'Word2VecParameters'}, 'model_id': None, 'training_frame': {'__meta': {'schema_version': 3, 'schema_name': 'FrameKeyV3', 'schema_type': 'Key<Frame>'}, 'name': 'Key_Frame__upload_b05cc6655ebae6fad56abe059f544d16.hex', 'type': 'Key<Frame>', 'URL': '/3/Frames/Key_Frame__upload_b05cc6655ebae6fad56abe059f544d16.hex'}, 'validation_frame': None, 'nfolds': 0, 'keep_cross_validation_models': True, 'keep_cross_validation_predictions': False, 'keep_cross_validation_fold_assignment': False, 'parallelize_cross_validation': True, 'distribution': 'AUTO', 'tweedie_power': 1.5, 'quantile_alpha': 0.5, 'huber_alpha': 0.9, 'response_column': None, 'weights_column': None, 'offset_column': None, 'fold_column': None, 'fold_assignment': 'AUTO', 'categorical_encoding': 'AUTO', 'max_categorical_levels': 10, 'ignored_columns': None, 'ignore_const_cols': True, 'score_each_iteration': False, 'checkpoint': None, 'stopping_rounds': 0, 'max_runtime_secs': 0.0, 'stopping_metric': 'AUTO', 'stopping_tolerance': 0.001, 'gainslift_bins': -1, 'custom_metric_func': None, 'custom_distribution_func': None, 'export_checkpoints_dir': None, 'auc_type': 'AUTO', 'vec_size': 100, 'window_size': 5, 'sent_sample_rate': 0.001, 'norm_model': 'HSM', 'epochs': 5, 'min_word_freq': 5, 'init_learning_rate': 0.025, 'word_model': 'SkipGram', 'pre_trained': None}\n    messages = [{'__meta': {'schema_version': 3, 'schema_name': 'ValidationMessageV3', 'schema_type': 'ValidationMessage'}, 'message_type': 'TRACE', 'field_name': 'keep_cross_validation_models', 'message': 'Only for cross-validation.'}, {'__meta': {'schema_version': 3, 'schema_name': 'ValidationMessageV3', 'schema_type': 'ValidationMessage'}, 'message_type': 'TRACE', 'field_name': 'keep_cross_validation_predictions', 'message': 'Only for cross-validation.'}, {'__meta': {'schema_version': 3, 'schema_name': 'ValidationMessageV3', 'schema_type': 'ValidationMessage'}, 'message_type': 'TRACE', 'field_name': 'keep_cross_validation_fold_assignment', 'message': 'Only for cross-validation.'}, {'__meta': {'schema_version': 3, 'schema_name': 'ValidationMessageV3', 'schema_type': 'ValidationMessage'}, 'message_type': 'TRACE', 'field_name': 'fold_assignment', 'message': 'Only for cross-validation.'}, {'__meta': {'schema_version': 3, 'schema_name': 'ValidationMessageV3', 'schema_type': 'ValidationMessage'}, 'message_type': 'TRACE', 'field_name': 'tweedie_power', 'message': 'Only for Tweedie Distribution.'}, {'__meta': {'schema_version': 3, 'schema_name': 'ValidationMessageV3', 'schema_type': 'ValidationMessage'}, 'message_type': 'TRACE', 'field_name': 'response_column', 'message': 'Ignored for unsupervised methods.'}, {'__meta': {'schema_version': 3, 'schema_name': 'ValidationMessageV3', 'schema_type': 'ValidationMessage'}, 'message_type': 'TRACE', 'field_name': 'balance_classes', 'message': 'Ignored for unsupervised methods.'}, {'__meta': {'schema_version': 3, 'schema_name': 'ValidationMessageV3', 'schema_type': 'ValidationMessage'}, 'message_type': 'TRACE', 'field_name': 'class_sampling_factors', 'message': 'Ignored for unsupervised methods.'}, {'__meta': {'schema_version': 3, 'schema_name': 'ValidationMessageV3', 'schema_type': 'ValidationMessage'}, 'message_type': 'TRACE', 'field_name': 'max_after_balance_size', 'message': 'Ignored for unsupervised methods.'}, {'__meta': {'schema_version': 3, 'schema_name': 'ValidationMessageV3', 'schema_type': 'ValidationMessage'}, 'message_type': 'TRACE', 'field_name': 'max_confusion_matrix_size', 'message': 'Ignored for unsupervised methods.'}, {'__meta': {'schema_version': 3, 'schema_name': 'ValidationMessageV3', 'schema_type': 'ValidationMessage'}, 'message_type': 'ERRR', 'field_name': 'train', 'message': 'The first column of the training input frame has to be column of Strings.'}]\n    error_count = 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mH2OResponseError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-37148911c770>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2vec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mH2OWord2vecEstimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mword_vectors_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH2OWord2vecEstimator\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"word_vectors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mword_vectors_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/h2o/estimators/estimator_base.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y, training_frame, offset_column, fold_column, weights_column, validation_frame, max_runtime_secs, ignored_columns, model_id, verbose)\u001b[0m\n\u001b[1;32m    121\u001b[0m                                  \u001b[0mvalidation_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_runtime_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_runtime_secs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                                  ignored_columns=ignored_columns, model_id=model_id, verbose=verbose)\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/h2o/estimators/estimator_base.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, parms, verbose)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mrest_ver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_rest_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mmodel_builder_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST /%d/ModelBuilders/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrest_ver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH2OJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_builder_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgo\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Model Build\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/h2o/h2o.py\u001b[0m in \u001b[0;36mapi\u001b[0;34m(endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;31m# type checks are performed in H2OConnection class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0m_check_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mh2oconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0msave_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_end_transaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36m_process_response\u001b[0;34m(response, save_to)\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m404\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m412\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH2OErrorV3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_stacktrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mH2OResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m         \u001b[0;31m# Server errors (notably 500 = \"Server Error\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mH2OResponseError\u001b[0m: ModelBuilderErrorV3  (water.exceptions.H2OModelBuilderIllegalArgumentException):\n    timestamp = 1648859996532\n    error_url = '/3/ModelBuilders/word2vec'\n    msg = 'Illegal argument(s) for Word2Vec model: word_vectors.  Details: ERRR on field: _train: The first column of the training input frame has to be column of Strings.'\n    dev_msg = 'Illegal argument(s) for Word2Vec model: word_vectors.  Details: ERRR on field: _train: The first column of the training input frame has to be column of Strings.'\n    http_status = 412\n    values = {'messages': [{'_log_level': 5, '_field_name': '_keep_cross_validation_models', '_message': 'Only for cross-validation.'}, {'_log_level': 5, '_field_name': '_keep_cross_validation_predictions', '_message': 'Only for cross-validation.'}, {'_log_level': 5, '_field_name': '_keep_cross_validation_fold_assignment', '_message': 'Only for cross-validation.'}, {'_log_level': 5, '_field_name': '_fold_assignment', '_message': 'Only for cross-validation.'}, {'_log_level': 5, '_field_name': '_tweedie_power', '_message': 'Only for Tweedie Distribution.'}, {'_log_level': 5, '_field_name': '_response_column', '_message': 'Ignored for unsupervised methods.'}, {'_log_level': 5, '_field_name': '_balance_classes', '_message': 'Ignored for unsupervised methods.'}, {'_log_level': 5, '_field_name': '_class_sampling_factors', '_message': 'Ignored for unsupervised methods.'}, {'_log_level': 5, '_field_name': '_max_after_balance_size', '_message': 'Ignored for unsupervised methods.'}, {'_log_level': 5, '_field_name': '_max_confusion_matrix_size', '_message': 'Ignored for unsupervised methods.'}, {'_log_level': 1, '_field_name': '_train', '_message': 'The first column of the training input frame has to be column of Strings.'}], 'algo': 'Word2Vec', 'parameters': {'_train': {'name': 'Key_Frame__upload_b05cc6655ebae6fad56abe059f544d16.hex', 'type': 'Key'}, '_valid': None, '_nfolds': 0, '_keep_cross_validation_models': True, '_keep_cross_validation_predictions': False, '_keep_cross_validation_predictions_precision': -1, '_keep_cross_validation_fold_assignment': False, '_parallelize_cross_validation': True, '_auto_rebalance': True, '_preprocessors': None, '_seed': -1, '_fold_assignment': 'AUTO', '_categorical_encoding': 'AUTO', '_max_categorical_levels': 10, '_distribution': 'AUTO', '_tweedie_power': 1.5, '_quantile_alpha': 0.5, '_huber_alpha': 0.9, '_ignored_columns': None, '_ignore_const_cols': True, '_weights_column': None, '_offset_column': None, '_fold_column': None, '_treatment_column': None, '_check_constant_response': True, '_is_cv_model': False, '_cv_fold': -1, '_score_each_iteration': False, '_max_runtime_secs': 0.0, '_stopping_rounds': 0, '_stopping_metric': 'AUTO', '_stopping_tolerance': 0.001, '_response_column': None, '_balance_classes': False, '_max_after_balance_size': 5.0, '_class_sampling_factors': None, '_max_confusion_matrix_size': 20, '_checkpoint': None, '_pretrained_autoencoder': None, '_custom_metric_func': None, '_custom_distribution_func': None, '_export_checkpoints_dir': None, '_gainslift_bins': -1, '_auc_type': 'AUTO', '_auuc_type': 'AUTO', '_auuc_nbins': -1, '_word_model': 'SkipGram', '_norm_model': 'HSM', '_min_word_freq': 5, '_vec_size': 100, '_window_size': 5, '_epochs': 5, '_init_learning_rate': 0.025, '_sent_sample_rate': 0.001, '_pre_trained': None}, 'error_count': 2}\n    exception_msg = 'Illegal argument(s) for Word2Vec model: word_vectors.  Details: ERRR on field: _train: The first column of the training input frame has to be column of Strings.'\n    stacktrace = ['water.exceptions.H2OModelBuilderIllegalArgumentException: Illegal argument(s) for Word2Vec model: word_vectors.  Details: ERRR on field: _train: The first column of the training input frame has to be column of Strings.\\n', '    water.exceptions.H2OModelBuilderIllegalArgumentException.makeFromBuilder(H2OModelBuilderIllegalArgumentException.java:19)', '    hex.ModelBuilder.trainModelOnH2ONode(ModelBuilder.java:334)', '    water.api.ModelBuilderHandler.handle(ModelBuilderHandler.java:51)', '    water.api.ModelBuilderHandler.handle(ModelBuilderHandler.java:16)', '    water.api.RequestServer.serve(RequestServer.java:470)', '    water.api.RequestServer.doGeneric(RequestServer.java:301)', '    water.api.RequestServer.doPost(RequestServer.java:227)', '    javax.servlet.http.HttpServlet.service(HttpServlet.java:707)', '    javax.servlet.http.HttpServlet.service(HttpServlet.java:790)', '    org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:865)', '    org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:535)', '    org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)', '    org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1317)', '    org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)', '    org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)', '    org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)', '    org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1219)', '    org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)', '    org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)', '    org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)', '    water.webserver.jetty9.Jetty9ServerAdapter$LoginHandler.handle(Jetty9ServerAdapter.java:130)', '    org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)', '    org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)', '    org.eclipse.jetty.server.Server.handle(Server.java:531)', '    org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:352)', '    org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)', '    org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:281)', '    org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:102)', '    org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)', '    org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)', '    org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)', '    org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)', '    org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)', '    org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)', '    org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:762)', '    org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:680)', '    java.lang.Thread.run(Thread.java:748)']\n    parameters = {'__meta': {'schema_version': 3, 'schema_name': 'Word2VecParametersV3', 'schema_type': 'Word2VecParameters'}, 'model_id': None, 'training_frame': {'__meta': {'schema_version': 3, 'schema_name': 'FrameKeyV3', 'schema_type': 'Key<Frame>'}, 'name': 'Key_Frame__upload_b05cc6655ebae6fad56abe059f544d16.hex', 'type': 'Key<Frame>', 'URL': '/3/Frames/Key_Frame__upload_b05cc6655ebae6fad56abe059f544d16.hex'}, 'validation_frame': None, 'nfolds': 0, 'keep_cross_validation_models': True, 'keep_cross_validation_predictions': False, 'keep_cross_validation_fold_assignment': False, 'parallelize_cross_validation': True, 'distribution': 'AUTO', 'tweedie_power': 1.5, 'quantile_alpha': 0.5, 'huber_alpha': 0.9, 'response_column': None, 'weights_column': None, 'offset_column': None, 'fold_column': None, 'fold_assignment': 'AUTO', 'categorical_encoding': 'AUTO', 'max_categorical_levels': 10, 'ignored_columns': None, 'ignore_const_cols': True, 'score_each_iteration': False, 'checkpoint': None, 'stopping_rounds': 0, 'max_runtime_secs': 0.0, 'stopping_metric': 'AUTO', 'stopping_tolerance': 0.001, 'gainslift_bins': -1, 'custom_metric_func': None, 'custom_distribution_func': None, 'export_checkpoints_dir': None, 'auc_type': 'AUTO', 'vec_size': 100, 'window_size': 5, 'sent_sample_rate': 0.001, 'norm_model': 'HSM', 'epochs': 5, 'min_word_freq': 5, 'init_learning_rate': 0.025, 'word_model': 'SkipGram', 'pre_trained': None}\n    messages = [{'__meta': {'schema_version': 3, 'schema_name': 'ValidationMessageV3', 'schema_type': 'ValidationMessage'}, 'message_type': 'TRACE', 'field_name': 'keep_cross_validation_models', 'message': 'Only for cross-validation.'}, {'__meta': {'schema_version': 3, 'schema_name': 'ValidationMessageV3', 'schema_type': 'ValidationMessage'}, 'message_type': 'TRACE', 'field_name': 'keep_cross_validation_predictions', 'message': 'Only for cross-validation.'}, {'__meta': {'schema_version': 3, 'schema_name': 'ValidationMessageV3', 'schema_type': 'ValidationMessage'}, 'message_type': 'TRACE', 'field_name': 'keep_cross_validation_fold_assignment', 'message': 'Only for cross-validation.'}, {'__meta': {'schema_version': 3, 'schema_name': 'ValidationMessageV3', 'schema_type': 'ValidationMessage'}, 'message_type': 'TRACE', 'field_name': 'fold_assignment', 'message': 'Only for cross-validation.'}, {'__meta': {'schema_version': 3, 'schema_name': 'ValidationMessageV3', 'schema_type': 'ValidationMessage'}, 'message_type': 'TRACE', 'field_name': 'tweedie_power', 'message': 'Only for Tweedie Distribution.'}, {'__meta': {'schema_version': 3, 'schema_name': 'ValidationMessageV3', 'schema_type': 'ValidationMessage'}, 'message_type': 'TRACE', 'field_name': 'response_column', 'message': 'Ignored for unsupervised methods.'}, {'__meta': {'schema_version': 3, 'schema_name': 'ValidationMessageV3', 'schema_type': 'ValidationMessage'}, 'message_type': 'TRACE', 'field_name': 'balance_classes', 'message': 'Ignored for unsupervised methods.'}, {'__meta': {'schema_version': 3, 'schema_name': 'ValidationMessageV3', 'schema_type': 'ValidationMessage'}, 'message_type': 'TRACE', 'field_name': 'class_sampling_factors', 'message': 'Ignored for unsupervised methods.'}, {'__meta': {'schema_version': 3, 'schema_name': 'ValidationMessageV3', 'schema_type': 'ValidationMessage'}, 'message_type': 'TRACE', 'field_name': 'max_after_balance_size', 'message': 'Ignored for unsupervised methods.'}, {'__meta': {'schema_version': 3, 'schema_name': 'ValidationMessageV3', 'schema_type': 'ValidationMessage'}, 'message_type': 'TRACE', 'field_name': 'max_confusion_matrix_size', 'message': 'Ignored for unsupervised methods.'}, {'__meta': {'schema_version': 3, 'schema_name': 'ValidationMessageV3', 'schema_type': 'ValidationMessage'}, 'message_type': 'ERRR', 'field_name': 'train', 'message': 'The first column of the training input frame has to be column of Strings.'}]\n    error_count = 2\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators.word2vec import H2OWord2vecEstimator\n",
    "word_vectors_model = H2OWord2vecEstimator( model_id = \"word_vectors\", vec_size = 100)\n",
    "word_vectors_model.train(training_frame = frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "quantitative-vitamin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model trained yet\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-reserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec - trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access vectors for specific words with a keyed lookup:\n",
    "vectort = word_vectors['easy']\n",
    "# see the shape of the vector (300,)\n",
    "vectort.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_obj = Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(tokenized_sent)\n",
    "sequences = tokenizer_obj.texts_to_sequences(tokenized_sent)\n",
    "\n",
    "word_index = tokenizer_obj.word_index\n",
    "print(\"unique tokens - \"+str(len(word_index)))\n",
    "vocab_size = len(tokenizer_obj.word_index) + 1\n",
    "print('vocab_size - '+str(vocab_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(tokenized_sent) + 1, embedding_dim))\n",
    "for word, i in tokenized_sent.items():\n",
    "    if word in word2vec_model: \n",
    "        embedding_vector = word2vec_model[word]\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
